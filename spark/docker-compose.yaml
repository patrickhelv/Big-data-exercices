version: "3.8"

name: "Pyspark cluster"

services:
  spark:
    container_name: spark
    hostname: spark # really important
    build: 
      context: .
      dockerfile: ./Dockerfiles/dockerfile_master.Dockerfile
    ports:
      - "7077:7077"
      - "8080:8080" # Exposes 8080 to the host
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_LOCAL_HOSTNAME=spark
      - SPARK_MASTER_HOST=spark
    networks:
    - spark_network
    volumes:
      - ./data:/data
    healthcheck:
      test: ["CMD", "nc", "-z", "spark", "7077"]  # Checks if port 7077 is open
      interval: 10s
      timeout: 5s
      retries: 10
    
  spark_worker:
    container_name: spark_worker
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    networks:
      - spark_network
    depends_on:
      spark:
        condition: service_healthy
  
  cleanup:
    image: docker:latest
    command: /bin/sh -c "docker ps -q --filter 'ancestor=moby/buildkit:buildx-stable-1' | xargs -r docker stop && docker ps -aq --filter 'ancestor=moby/buildkit:buildx-stable-1' | xargs -r docker rm"
    networks:
      - spark_network
    depends_on:
      - spark
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

networks:
  spark_network:
    name: spark_network
    driver: bridge

volumes:
  data: {}
